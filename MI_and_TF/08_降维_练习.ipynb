{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1题\n",
    "减少数据集维度的主要动机是什么？主要缺点是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 动机\n",
    "* 为了加速后续的训练算法（在某些情况下，它甚至可以消除噪声和冗余特征，使得训练算法性能更好）\n",
    "* 可视化数据并获取最重要特征的展示\n",
    "* 节省空间（压缩）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺点\n",
    "* 由于信息丢失，可能造成算法性能的降低\n",
    "* 它可以是计算密集型的\n",
    "* 在机器学习流水线过程中增加了一些复杂性\n",
    "* 变换的特征难以解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2题\n",
    "什么是维度爆炸？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 维度爆炸是指在低维空间中不存在的许多问题出现在高维空间中；在机器学习中，一种常见的表现是随机抽样的高维向量通常非常稀疏，增加了过度拟合的风险，并且使得在没有大量训练数据的情况下识别数据中的规律变得非常困难**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3题\n",
    "一旦对某数据集降维，我们可能恢复它吗？如果可以，怎样做才能恢复？如果不可以，为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一旦使用我们讨论的算法之一减少了数据集的维度，几乎总是不可能完全回复的，因为在降维过程中会丢失一些信息。此外，虽然一些算法（如PCA）具有简单的逆向变换过程，可以重建与原始数据集相对相似的数据集，但其他算法（如T-SNE）则不会**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4题\n",
    "PCA 可以用于降低一个高度非线性对数据集吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA可以用来显著减少大多数数据集的维数，即使它们是高度非线性的，因为它至少可以消除无用的维数。 但是，如果没有无用的维度 - 例如瑞士卷 - 那么使用PCA降低维度会损失太多信息。 你想展开瑞士卷，而不是挤压它。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5题\n",
    "假设你对一个 1000 维的数据集应用 PCA，同时设置方差解释率为 95%，你的最终数据集将会有多少维？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **这是个棘手的问题：它取决于数据集。 我们来看两个极端的例子。 首先，假设数据集由几乎完全对齐的点组成。 在这种情况下，PCA可以将数据集简化为一维，同时仍保留95％的方差。 现在想象一下，数据集由完全随机的点组成，散布在1,000个维度上。 在这种情况下，需要所有1,000个维度来保留95％的方差。 所以答案是，它取决于数据集，它可以是1到1,000之间的任何数字**\n",
    "* ** 绘制（解释的方差 — 维数）图是获得数据集固有维度的一种粗略方式。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6题\n",
    "在什么情况下你会使用普通的 PCA，增量 PCA，随机 PCA 和核 PCA？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **数据集适合内存的情况下，建议使用普通的PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **对于不适合内存的大型数据集，建议使用增量PCA，但它比常规PCA更慢；增量PCA对于在线任务也很有用，比如需要应用PCA到随时有新实例进来的任务时**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **当考虑大大降低数据集维度，并且数据集适合内存，随机PCA是非常有用的；在这种情况下，它比普通PCA快得多**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **核PCA对于非线性数据集非常有用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7题\n",
    "你该如何评价你的降维算法在你数据集上的表现？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**直观地说，如果一个维度减少算法从数据集中消除了很多维度而不会丢失太多的信息，它就表现出色。 测量这种方法的一种方法是应用逆向变换并测量重建误差。 但是，并非所有的降维算法都提供了相反的转换。 或者，如果您在另一个机器学习算法（例如，随机森林分类器）之前将维度降低用作预处理步骤，那么您可以简单地测量第二个算法的性能; 如果降维不会损失太多信息，那么该算法应该与使用原始数据集时一样好。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8题\n",
    "将两个不同的降维算法串联使用有意义吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**串联两种不同的降维算法绝对有意义。 一个常见的例子是使用PCA来快速消除大量无用的维度，然后应用另一种更慢的维度降低算法，如LLE。 这种两步叠加产生的性能可能与仅使用LLE算法降维相同，但所需要的时间很短。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9题\n",
    "加载 MNIST 数据集（在第 3 章中介绍），并将其分成一个训练集和一个测试集（将前 60,000 个实例用于训练，其余 10,000 个用于测试）。在数据集上训练一个随机森林分类器，并记录了花费多长时间，然后在测试集上评估模型。接下来，使用 PCA 降低数据集的维度，设置方差解释率为 95%。在降维后的数据集上训练一个新的随机森林分类器，并查看需要多长时间。训练速度更快？接下来评估测试集上的分类器：它与以前的分类器比较起来如何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST origin')\n",
    "\n",
    "X_train = mnist['data'][: 60000]\n",
    "y_train = mnist['target'][: 60000]\n",
    "\n",
    "X_test = mnist['data'][60000, :]\n",
    "y_test = mnist['data'][60000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 使用随机森林**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rfc_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "rfc_clf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))\n",
    "\n",
    "y_pred = rfc_clf.predict(X_test)\n",
    "accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_componts=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "rfc_clf2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "rfc_clf2.fit(X_train_reduced)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))\n",
    "\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "y_pred = rfc_clf2.predict(X_test_reduced)\n",
    "accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 使用逻辑回归**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(mult_class='multinomial', solver='lbfgs', random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))\n",
    "\n",
    "y_pred = lr_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10题\n",
    "使用 t-SNE 将 MNIST 数据集缩减到二维，并使用 Matplotlib 绘制结果图。您可以使用 10 种不同颜色的散点图来表示每个图像的目标类别。或者，您可以在每个实例的位置写入彩色数字，甚至可以绘制数字图像本身的降维版本（如果绘制所有数字，则可视化可能会过于混乱，因此您应该绘制随机样本或只在周围没有其他实例被绘制的情况下绘制）。你将会得到一个分隔良好的的可视化数字集群。尝试使用其他降维算法，如 PCA，LLE 或 MDS，并比较可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=r'C:\\Users\\Zeke\\my_code\\Learning\\Machine-Learning-and-Practice\\MI_and_TF\\datasets')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
