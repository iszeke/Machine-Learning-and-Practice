{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1题\n",
    "如果你在相同训练集上训练 5 个不同的模型，它们都有 95% 的准确率，那么你是否可以通过组合这个模型来得到更好的结果？如果可以那怎么做呢？如果不可以请给出理由。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "答：可以尝试将5个模型组合成一个voting ensemble。如果模型选择不同，比如有支持向量机，决策树，逻辑回归等，结果会比较好；而如果他们基于不同的实例训练（bagging，pasting），结果会更好\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2题\n",
    "软投票和硬投票分类器之间有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "答：硬投票分类器只统计emsemble中每个分类器的结果，并挑选获得最多投票的数；软投票分类器计算分类器对每个类别的平均概率估计，然后以最高概率挑选类别，一般软投票表现更好，但必须分类器能估计概率时才可以用，对于SVM分类器，必须设置probability=True才可以使用软类别估计器\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3题\n",
    "是否有可能通过分配多个服务器来加速 bagging 集成系统的训练？pasting 集成，boosting 集成，随机森林，或 stacking 集成怎么样？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "答：通过分配多个服务器，可以加速 bagging集成 的训练，因为 bagging集成 中的每个预测器都独立于其它预测器，同样，pasting集成与随机森林也一样。 但是，boosting集成中的每个预测器都是基于之前的预测器构建的，因此训练必然是连续的，所以难以将训练分布到多个服务器训练。 对于stacking 集成，第一层中的预测器是相互独立的，可以在多台服务器上并行进行训练，不过，blender层预测器只能在第一层中的预测变量全部被训练后才能被训练。\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4题\n",
    "out-of-bag 评估的好处是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "通过out-of-bag，可以使用每个预测器并未使用的那部分实例进行评估，这可以对ensemble进行公正的评估，而不需要额外的验证集，因此，你可以使用更多的实例进行训练，这样你的模型的性能会稍微好点\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5题\n",
    "是什么使 Extra-Tree 比规则随机森林更随机呢？这个额外的随机有什么帮助呢？那这个 Extra-Tree 比规则随机森林谁更快呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对于随机森林，树在生长过程中，节点的分裂仅仅考虑特征的随机子集；\n",
    "* 对于Extra-Tree，它不仅使用随机子集，并且，节点的分裂不使用常规决策树使用的最佳阈值分割，而是对每个特征设置随机阈值进行分割。\n",
    "* 这种所处的随机过程更像一种正则化：如果随机森林发生过拟合，Extra-Tree可能表现会更好。在训练时，Extra-Tree更快，但是在预测时，两者差不多。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6题\n",
    "如果你的 Adaboost 模型欠拟合，那么你需要怎么调整超参数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.ensemble.AdaBoostClassifier(base_estimator=None, \n",
    "                                    n_estimators=50, \n",
    "                                    learning_rate=1.0, \n",
    "                                    algorithm='SAMME.R', \n",
    "                                    random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (1) 增加n_estimators\n",
    "* (2) 降低base_estimator的正则化超参数\n",
    "* (3) 稍微提高学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7题\n",
    "如果你的梯度提升过拟合，那么你应该调高还是调低学习率呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** \n",
    "答：应该尝试降低学习率，也可以使用提前停止找到最佳的预测器\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8题\n",
    "导入 MNIST 数据（第三章中介绍），把它切分进一个训练集，一个验证集，和一个测试集（例如 40000 个实例进行训练，10000 个进行验证，10000 个进行测试）。然后训练多个分类器，例如一个随机森林分类器，一个 Extra-Tree 分类器和一个 SVM。接下来，尝试将它们组合成集成，使用软或硬投票分类器来胜过验证集上的所有集合。一旦找到了，就在测试集上实验。与单个分类器相比，它的性能有多好？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（1）分割训练集，验证集，测试集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = fetch_mldata('MNIST origin')\n",
    "\n",
    "# 分割训练集，验证集，测试集\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, test_size=10000, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（2）训练多个分类器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "rfc_clf = RandomForestClassifier(random_state=42)\n",
    "etc_clf = ExtraTreesClassifier(random_state=42)\n",
    "svm_clf = LinearSVC(random_state=42)\n",
    "mlp_clf = MLPClassifier(randoom_state=42)\n",
    "\n",
    "estimators = [rfc_clf, etc_clf, svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print('Train the: ', estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（3）硬分类集合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "named_estimators = [('rfc_clf', rfc_clf),\n",
    "                    ('etc_clf', etc_clf),\n",
    "                    ('svm_clf', svm_clf),\n",
    "                    ('mlp_clf', mlp_clf)]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=named_estimators,voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除SVM，查看性能变化\n",
    "del voting_clf.estimators_[2]\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（4）软分类集合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = 'soft'\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（5）测试集性能评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9题\n",
    "运行练习8中的所有单个分类器，对验证集进行预测，得到验证集的预测向量，将此向量作为X，依然将验证的y作为y，使用算法进行blender的训练，得到blender分类器。\n",
    "\n",
    "然后，使用训练的blender分类器，对测试集进行预测，查看此分类器结果相比于第8题的投票分类器如何？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（1）所有模型预测验证集得到的结果作为blender的输入向量，y_val作为输出向量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_predictions = np.empty((len(X_val),len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "\n",
    "X_val_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（2）使用RandomForestClassifier训练blender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以尝试其他方法，不局限于随机森林\n",
    "rfc_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rfc_blender.fit(X_val_predicts, y_val)\n",
    "rfc_blender.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**（3）使用训练的bleder对测试集进行预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_test_pred = rfc_blender.predict(X_test_predictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
